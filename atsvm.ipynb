{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "T=5\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Auxiliary_Classifier:\n",
    "    def __init__(self, C, k, n_features):\n",
    "        self.C = C  # Regularization parameter\n",
    "        self.k = k  # Number of classes\n",
    "        self.omega = np.random.rand(k, n_features)  # Weights\n",
    "        self.b = np.random.rand(k)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        L = np.zeros((n_samples, self.k))\n",
    "        mask = np.zeros((n_samples, self.k))\n",
    "\n",
    "        print(\"SVM Shapes\", self.omega.T.shape, X[0].shape, self.b.shape, y.shape)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            for j in range(self.k):\n",
    "                if j != y[i]:\n",
    "                    margin = self.omega[y[i], j] @ X[i] - self.omega[y[i]] @ X[i] + self.b[j] - self.b[y[i]]\n",
    "                    L[i, j] = max(0, 1 - margin)\n",
    "                    if L[i, j] > 0:\n",
    "                        mask[i, j] = 1\n",
    "\n",
    "        # print(X.shape, mask.shape, L.shape, y.shape)\n",
    "\n",
    "        for j in range(self.k):\n",
    "            if j in y:\n",
    "                indices = np.where(y == j)[0]\n",
    "                omega_grad = np.sum(X[indices][:, np.newaxis, :] * mask[indices][:, :, np.newaxis], axis=0)\n",
    "                self.omega[j] -= omega_grad.mean(axis=0) - self.C * self.omega[j]\n",
    "\n",
    "                b_grad = mask[indices].sum(axis=0)\n",
    "                self.b[j] -= b_grad.mean() - self.C * self.b[j]\n",
    "\n",
    "        return mask, L\n",
    "\n",
    "    def predict(self, X):\n",
    "        decision_function = X @ self.omega.T + self.b\n",
    "        return np.argmax(decision_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "Epoch 1/5 finished, Loss: 3138.901611328125, Accuracy: 7.535%\n",
      "Epoch 2/5 finished, Loss: 3174.666259765625, Accuracy: 7.421%\n",
      "Epoch 3/5 finished, Loss: 3183.661376953125, Accuracy: 7.503%\n",
      "Epoch 4/5 finished, Loss: 3186.893310546875, Accuracy: 7.461%\n",
      "Epoch 5/5 finished, Loss: 3141.361083984375, Accuracy: 7.488%\n",
      "Finished Training. SVM auxiliary classifier will be removed for inference.\n",
      "Accuracy: 11.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "\n",
    "def pgd_attack(image, epsilon, data_grad, num_steps=10, step_size=2/255):\n",
    "    perturbed_image = image.clone().detach()\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        perturbed_image += step_size * sign_data_grad\n",
    "        perturbed_image = torch.clamp(perturbed_image, image - epsilon, image + epsilon)\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image.detach().to(\"cpu\").numpy()\n",
    "\n",
    "def generate_pgd_attacks(model, images, labels):\n",
    "    perturbed_images = []\n",
    "    images.requires_grad = True\n",
    "    output = model(images)\n",
    "    loss = criterion(output, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    data_grad = images.grad.data\n",
    "    for i in range(images.shape[0]):\n",
    "        perturbed_images.append(pgd_attack(images[i], 8/255, data_grad[i]))\n",
    "    \n",
    "    return np.array(perturbed_images)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=625, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(test_dataset, batch_size=625, shuffle=False, drop_last=True)\n",
    "\n",
    "resnet18 = models.resnet18(num_classes=10)\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet18.children())[:-1])\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=75, gamma=0.1)\n",
    "\n",
    "print(resnet18.fc.in_features)\n",
    "\n",
    "# svm_classifier = SVM_Auxiliary_Classifier(C=1, k=10, n_features=trainloader.batch_size * 2)\n",
    "svm_classifier = SVC(decision_function_shape='ovr')\n",
    "resnet18.train()\n",
    "\n",
    "for epoch in range(T):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        adv_inputs = torch.tensor(generate_pgd_attacks(resnet18, inputs, labels))\n",
    "        adv_inputs = adv_inputs.to(device)\n",
    "\n",
    "        total_inputs = torch.cat((adv_inputs, inputs), 0)\n",
    "\n",
    "        labels = torch.cat((torch.tensor([0] * labels.shape[0]).to(device), labels), 0)\n",
    "\n",
    "        adv_inputs = adv_inputs.to(device)\n",
    " \n",
    "        # Get features before the last FC layer\n",
    "        features = feature_extractor(total_inputs)\n",
    "        # print(features.shape)\n",
    "\n",
    "        mask = np.zeros((trainloader.batch_size * 2))\n",
    "        l_margin = np.zeros((trainloader.batch_size * 2, 10))\n",
    "\n",
    "        svm_classifier.fit(features.cpu().detach().squeeze().numpy(), labels.cpu().numpy())\n",
    "\n",
    "        distances = svm_classifier.decision_function(features.cpu().detach().squeeze().numpy())\n",
    "\n",
    "        l_margin = np.maximum(0, 1 - distances + distances[range(trainloader.batch_size * 2), labels.cpu().numpy()][:, np.newaxis])\n",
    "\n",
    "        mask = (l_margin > 0).any(axis=1).astype(int)\n",
    "\n",
    "        # print(mask)\n",
    "\n",
    "        # exit()\n",
    "        # print(mask.shape)\n",
    "\n",
    "        outputs = resnet18(total_inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        # for i in range(outputs.size(0)):\n",
    "        #     loss += criterion2(outputs[i], labels[i]).detach().cpu() * mask[i]\n",
    "\n",
    "        # print(mask.shape, l_margin.shape, loss.shape)\n",
    "        # print(\"BRUH\", criterion(outputs, labels).shape)\n",
    "\n",
    "        loss = (criterion2(outputs, labels) * torch.from_numpy(mask).float().to(device)).sum()\n",
    "\n",
    "        # print(loss)\n",
    "\n",
    "        loss = loss.to(device, dtype=torch.float32)\n",
    "        l_margin = torch.tensor(l_margin).float().to(device)\n",
    "\n",
    "        total_loss = (loss + 0.1 * l_margin).mean().clone().detach().requires_grad_(True)\n",
    "\n",
    "        # print(total_loss)\n",
    "        # total_loss = total_loss.requires_grad_(True)\n",
    "        # print(total_loss, loss, L_margin.mean())\n",
    "        total_loss.backward()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{T} finished, Loss: {total_loss.item()}, Accuracy: {100 * correct / total}%')\n",
    "\n",
    "print('Finished Training. SVM auxiliary classifier will be removed for inference.')\n",
    "\n",
    "resnet18.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy: {100 * correct / total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
